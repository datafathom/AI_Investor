
import os
import sys
import json
from pathlib import Path
import logging
from typing import Any, Dict

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

logger = logging.getLogger(__name__)

# Inject Any and Dict into builtins to avoid NameErrors in blueprints during static import
import builtins
import typing
builtins.Any = typing.Any
builtins.Dict = typing.Dict
builtins.List = typing.List
builtins.Optional = typing.Optional
builtins.Union = typing.Union

def build_docs(**kwargs):
    """
    Build OpenAPI Specification and Postman Collection.
    """
    print("Building API Documentation artifacts...")
    
    # Mocking infrastructure to prevent connection errors during import/init
    _mock_infrastructure()
    
    try:
        from web.app import create_app
        app, _ = create_app()
        
        # 1. Generate OpenAPI Spec via Flasgger
        with app.app_context():
            swag = None
            if hasattr(app, 'extensions') and 'flasgger' in app.extensions:
                swag = app.extensions['flasgger']
            
            if not swag:
                print("Warning: Flasgger not found in app.extensions. Trying to initialize manually.")
                from flasgger import Swagger
                try:
                    swag = Swagger(app, endpoint='apispec_autogenerated_runner')
                except Exception as e:
                    print(f"Error initializing Swagger in runner: {e}")
            
            if swag:
                spec_data = swag.get_apispecs()
            else:
                spec_data = _generate_manual_spec(app)
            
        # Save OpenAPI JSON
        docs_dir = PROJECT_ROOT / "docs" / "api"
        docs_dir.mkdir(parents=True, exist_ok=True)
        
        openapi_path = docs_dir / "openapi.json"
        with open(openapi_path, "w") as f:
            json.dump(spec_data, f, indent=2)
        print(f"Generated OpenAPI Spec: {openapi_path}")
        
        # 2. Generate Postman Collection from OpenAPI Spec
        postman_collection = _convert_to_postman(spec_data)
        postman_path = docs_dir / "ai_investor_postman_collection.json"
        with open(postman_path, "w") as f:
            json.dump(postman_collection, f, indent=2)
        print(f"Generated Postman Collection: {postman_path}")
        
    except Exception as e:
        print(f"Failed to build documentation: {e}")
        import traceback
        traceback.print_exc()

def build_api_routes_txt(**kwargs):
    """Generates notes/api_routes.txt from live Flask app."""
    print("Generating API Routes (TXT)...")
    _mock_infrastructure()
    try:
        from web.app import create_app
        app, _ = create_app()
        spec = _generate_manual_spec(app)
        
        output_path = PROJECT_ROOT / "notes" / "api_routes.txt"
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        paths = sorted(spec["paths"].keys())
        
        with open(output_path, "w", encoding="utf-8") as f:
            f.write("# AI Investor - Backend API Routes\n")
            f.write("=" * 40 + "\n\n")
            f.write("Base URL: http://localhost:5050\n\n")
            for path in paths:
                for method, details in spec["paths"][path].items():
                    f.write(f"- {method.upper():7} {path}\n")
                    # if details.get("summary"):
                    #    f.write(f"  {details['summary']}\n")
            
        print(f"SUCCESS: Generated {output_path}")
    except Exception as e:
        print(f"Error generating API routes TXT: {e}")

def build_api_routes_json(**kwargs):
    """Generates notes/api_routes.json from live Flask app."""
    print("Generating API Routes (JSON)...")
    _mock_infrastructure()
    try:
        from web.app import create_app
        app, _ = create_app()
        spec = _generate_manual_spec(app)

        output_path = PROJECT_ROOT / "notes" / "api_routes.json"
        
        routes_list = []
        for path, methods in spec["paths"].items():
            for method, details in methods.items():
                routes_list.append({
                    "path": path,
                    "method": method.upper(),
                    "summary": details.get("summary", "No summary"),
                    "parameters": details.get("parameters", {}),
                    "request_body": details.get("requestBody", None),
                    "response_body": details.get("responses", {}),
                    "error_codes": {"400": "Bad Request", "401": "Unauthorized", "500": "Server Error"},
                    "authentication": "Bearer Token" if "security" in details else "None",
                    "rate_limiting": "100/min",
                    "caching": None
                })
        
        # Sort by URL
        routes_list.sort(key=lambda x: x["path"])
        
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(routes_list, f, indent=2)
            
        print(f"SUCCESS: Generated {output_path}")
    except Exception as e:
        print(f"Error generating API routes JSON: {e}")
        import traceback
        traceback.print_exc()

def build_api_routes_postman(**kwargs):
    """Generates a date-stamped Postman Collection in notes/."""
    from datetime import datetime
    today = datetime.now().strftime("%Y-%m-%d")
    collection_name = f"AI_Investor_{today}_postmanCollection"
    
    print(f"Generating Postman Collection: {collection_name}...")
    _mock_infrastructure()
    try:
        from web.app import create_app
        app, _ = create_app()
        spec = _generate_manual_spec(app)
        
        postman_data = _convert_to_postman(spec, name=collection_name)
        
        output_path = PROJECT_ROOT / "notes" / f"{collection_name}.json"
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(postman_data, f, indent=2)
            
        print(f"SUCCESS: Generated {output_path}")
        print("You can now import this file into the Postman application.")
    except Exception as e:
        print(f"Error generating Postman collection: {e}")

def serve_docs(**kwargs):
    """
    Serve the Swagger UI locally.
    """
    port = kwargs.get("port", 7000)
    print(f"Serving Swagger UI on http://localhost:{port}/api/docs/swagger-ui ...")
    
    # We can just start the backend in a special 'docs-only' mode or just run it normally
    # But for a dedicated serve-docs, let's just use the existing backend infrastructure
    # but maybe with a clear message.
    
    os.environ["FLASK_APP"] = "web/app.py"
    os.environ["FLASK_ENV"] = "development"
    
    import subprocess
    cmd = [sys.executable, str(PROJECT_ROOT / "web" / "app.py")]
    
    print("Swagger UI will be available at: http://localhost:5050/api/docs/swagger-ui")
    print("ReDoc will be available at: http://localhost:5050/api/docs/redoc")
    
    subprocess.run(cmd)

def _generate_manual_spec(app):
    """Fallback generator that manually extracts routes from the Flask app."""
    print("Falling back to manual route extraction with docstring introspection...")
    spec = {
        "openapi": "3.0.0",
        "info": {
            "title": "AI Investor API (Auto-extrated)",
            "version": "1.0.0",
            "description": "API documentation generated via static introspection."
        },
        "paths": {},
        "components": {
            "securitySchemes": {
                "bearerAuth": {
                    "type": "http",
                    "scheme": "bearer",
                    "bearerFormat": "JWT"
                }
            }
        }
    }
    
    for rule in app.url_map.iter_rules():
        if rule.endpoint == 'static':
            continue
            
        path = str(rule)
        all_methods = [m.lower() for m in rule.methods]
        methods = [m for m in all_methods if m in ['get', 'post', 'put', 'delete', 'patch']]
        
        if not methods:
            continue

        # Get the view function for docstring extraction
        view_func = app.view_functions.get(rule.endpoint)
        docstring = view_func.__doc__ if view_func and view_func.__doc__ else None
        
        # Determine summary and description from docstring
        summary = f"Endpoint {rule.endpoint}"
        description = ""
        if docstring:
            doc_lines = [line.strip() for line in docstring.strip().split('\n')]
            if doc_lines:
                summary = doc_lines[0]
                description = "\n".join(doc_lines[1:]) if len(doc_lines) > 1 else ""

        # Check for security (simple heuristic for @login_required)
        is_secure = False
        if view_func:
            func_name = getattr(view_func, '__name__', '')
            # Flask-Login / Flask-JWT wrappers often contain these strings
            if 'decorated' in func_name or 'wrapper' in func_name:
                is_secure = True

        if path not in spec["paths"]:
            spec["paths"][path] = {}
            
        for method in methods:
            spec["paths"][path][method] = {
                "summary": summary,
                "description": description,
                "tags": [rule.endpoint.split('.')[0] if '.' in rule.endpoint else "General"],
                "responses": {"200": {"description": "OK"}}
            }
            if is_secure:
                spec["paths"][path][method]["security"] = [{"bearerAuth": []}]
            
    return spec

def _mock_infrastructure():
    """Monkeypatch database drivers to allow app initialization without live DBs."""
    from unittest.mock import MagicMock
    
    # Mock psycopg2 (Postgres)
    mock_psycopg2 = MagicMock()
    sys.modules["psycopg2"] = mock_psycopg2
    sys.modules["psycopg2.extras"] = MagicMock()
    sys.modules["psycopg2.pool"] = MagicMock()
    
    # Mock redis
    sys.modules["redis"] = MagicMock()
    
    # Mock kafka
    sys.modules["confluent_kafka"] = MagicMock()
    sys.modules["confluent_kafka.admin"] = MagicMock()
    
    # Mock neo4j
    sys.modules["neo4j"] = MagicMock()
    
    # Mock elasticsearch
    sys.modules["elasticsearch"] = MagicMock()

    print("Infrastructure drivers mocked for static inspection.")

# Category mapping for logical folder organization
CATEGORY_MAPPING = {
    # Authentication & Identity
    "ðŸ” Authentication & Identity": [
        "auth", "google_auth", "facebook_auth", "identity", "privacy", "kyc"
    ],
    # Market Data & Analysis
    "ðŸ“Š Market Data & Analysis": [
        "market", "macro", "macro_data", "news", "scanner", "stocktwits", "social"
    ],
    # Portfolio & Trading
    "ðŸ’¼ Portfolio & Trading": [
        "dashboard", "brokerage", "options", "paper_trading", "execution",
        "advanced_orders", "watchlist", "alert", "portfolio", "strategy"
    ],
    # Financial Planning
    "ðŸ¦ Financial Planning": [
        "financial_planning", "retirement", "estate", "tax", "tax_optimization",
        "budgeting", "credit", "billing", "cash"
    ],
    # AI & Automation
    "ðŸ¤– AI & Automation": [
        "ai", "evolution", "autocoder", "ai_autocoder", "predictions",
        "debate", "briefing", "research", "ml_training", "ai_assistant"
    ],
    # Web3 & Crypto
    "ðŸŒ Web3 & Crypto": [
        "crypto", "web3", "coinbase", "binance", "ethereum", "coinbase_crypto"
    ],
    # Wave APIs (Phases 57-68)
    "ðŸ“ˆ Wave APIs": [
        "backtest", "scenario", "compliance", "philanthropy", "corporate",
        "margin", "mobile", "integrations", "zen", "system", "estate_bp"
    ],
    # System & Admin
    "ðŸ”§ System & Admin": [
        "health", "General", "docs", "workspace", "enterprise", "institutional"
    ],
    # Payments & Billing
    "ðŸ’³ Payments & Billing": [
        "stripe", "paypal", "plaid", "venmo", "square", "payment_transfer"
    ],
    # Communication
    "ðŸ“§ Communication": [
        "communication", "twilio", "email", "discord", "youtube", "gmail"
    ],
}


def _get_category_for_tag(tag: str) -> str:
    """Map a tag to its parent category folder."""
    tag_lower = tag.lower().replace("-", "_").replace(" ", "_")
    for category, tags in CATEGORY_MAPPING.items():
        if tag_lower in [t.lower() for t in tags]:
            return category
    return "ðŸ“ Other"


def _convert_to_postman(openapi_spec, name="AI Investor API"):
    """
    Convert OpenAPI 2.0/3.0 to Postman Collection v2.1 format.
    Organizes endpoints into logical nested folder hierarchy.
    """
    info = openapi_spec.get("info", {})
    description = info.get("description", "API Collection")
    
    postman = {
        "info": {
            "_postman_id": "ai-investor-" + str(hash(name)),
            "name": name,
            "description": description,
            "schema": "https://schema.getpostman.com/json/collection/v2.1.0/collection.json"
        },
        "item": [],
        "variable": [
            {
                "key": "baseUrl",
                "value": "http://localhost:5050",
                "type": "string"
            },
            {
                "key": "token",
                "value": "YOUR_JWT_TOKEN_HERE",
                "type": "string"
            }
        ]
    }
    
    paths = openapi_spec.get("paths", {})
    
    # Nested structure: category -> tag -> items
    category_groups = {}
    
    for path, methods in paths.items():
        for method, details in methods.items():
            if method.lower() not in ["get", "post", "put", "delete", "patch"]:
                continue
                
            tags = details.get("tags", ["General"])
            primary_tag = tags[0]
            category = _get_category_for_tag(primary_tag)
            
            if category not in category_groups:
                category_groups[category] = {}
            if primary_tag not in category_groups[category]:
                category_groups[category][primary_tag] = []
                
            # Extract common parameters from path (e.g. <user_id>)
            import re
            path_variables = re.findall(r'<(\w+)>', path)
            postman_path = path.replace('<', ':').replace('>', '')
            
            # Create request item
            item = {
                "name": details.get("summary") or details.get("operationId") or f"{method.upper()} {path}",
                "request": {
                    "method": method.upper(),
                    "header": [
                        {
                            "key": "Content-Type",
                            "value": "application/json"
                        },
                        {
                            "key": "Authorization",
                            "value": "Bearer {{token}}",
                            "type": "text",
                            "description": "JWT Token"
                        }
                    ],
                    "url": {
                        "raw": "{{baseUrl}}" + postman_path,
                        "host": ["{{baseUrl}}"],
                        "path": postman_path.strip("/").split("/")
                    },
                    "description": details.get("description", "")
                }
            }
            
            # Add path variables to request
            if path_variables:
                item["request"]["url"]["variable"] = [
                    {"key": var, "value": f"example_{var}"} for var in path_variables
                ]
            
            # Extract query parameters from description
            query_params = []
            desc = details.get("description", "")
            query_match = re.search(r'(?:Query Params:|Query:)\n?(.*?(?=\n\n|\n[A-Z]|$))', desc, re.DOTALL | re.IGNORECASE)
            if query_match:
                param_text = query_match.group(1).strip()
                # matches "param_name: description" or "?param=val"
                param_lines = re.findall(r'(\w+):\s*.*|(\w+)\s*\(query\)', param_text)
                for p in param_lines:
                    p_name = p[0] or p[1]
                    if p_name:
                        query_params.append({"key": p_name, "value": f"{{{{{p_name}}}}}"})
            
            if query_params:
                item["request"]["url"]["query"] = query_params

            # Extract request body from description if it looks like JSON
            body_content = "{}"
            desc = details.get("description", "")
            if "{" in desc and "}" in desc:
                # Naive extraction of JSON blocks
                try:
                    json_match = re.search(r'\{.*\}', desc, re.DOTALL)
                    if json_match:
                        # Basic cleanup of common docstring artifacts
                        possible_json = json_match.group(0).replace("'", '"')
                        # Remove comments like # Optional
                        possible_json = re.sub(r'#.*', '', possible_json)
                        # Minimal attempt to validate
                        body_content = possible_json
                except:
                    pass

            if method.lower() in ["post", "put", "patch"]:
                item["request"]["body"] = {
                    "mode": "raw",
                    "raw": body_content,
                    "options": {
                        "raw": {
                            "language": "json"
                        }
                    }
                }
            
            category_groups[category][primary_tag].append(item)
    
    # Build nested folder structure
    for category in sorted(category_groups.keys()):
        tag_dict = category_groups[category]
        category_folder = {
            "name": category,
            "item": []
        }
        
        for tag in sorted(tag_dict.keys()):
            items = tag_dict[tag]
            tag_folder = {
                "name": tag.replace("_", " ").title(),
                "item": items
            }
            category_folder["item"].append(tag_folder)
        
        postman["item"].append(category_folder)
        
    return postman
