
import logging
import json
from utils.database_manager import get_database_manager
from services.system.audit_integrity_service import get_audit_integrity_service

logger = logging.getLogger(__name__)

class ActivityService:
    """
    Central service for logging system activities with immutable audit trails.
    """
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ActivityService, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        self.db = get_database_manager()
        self.audit_service = get_audit_integrity_service()

    def log_activity(self, user_id: str, activity_type: str, details: dict = None):
        """
        Logs an activity with a cryptographic integrity hash.
        """
        if details is None:
            details = {}
            
        try:
            with self.db.pg_cursor() as cur:
                # 1. Get the hash of the most recent record
                cur.execute("SELECT verification_hash FROM activity_logs ORDER BY created_at DESC LIMIT 1")
                res = cur.fetchone()
                previous_hash = res[0] if res else "GENESIS_HASH"
                
                # 2. Prepare data for insertion (UUID/Time will be generated by DB, but we need them for hash)
                # To ensure exact match, we should probably insert first returning ID/Created_At, or generate them in python.
                # However, for immutability, the hash must be generated BEFORE final commitment or updated immediately.
                # STRATEGY: Generate ID in python to include in hash.
                
                # Note: Migration uses gen_random_uuid(), but we can override it or select it back.
                # Let's use INSERT RETURNING to get generated values, then UPDATE with hash?
                # BETTER: Include predictable data in hash only? No, we need to bind the ID.
                # Let's generate UUID here if possible? Or trust database generation and update in transaction.
                
                # Transactional Approach:
                # 1. Insert record with null hash
                # 2. Get ID, Created_At
                # 3. Calculate Hash
                # 4. Update Record
                
                cur.execute("""
                    INSERT INTO activity_logs (user_id, activity_type, details, previous_hash)
                    VALUES (%s, %s, %s, %s)
                    RETURNING id, created_at
                """, (user_id, activity_type, json.dumps(details), previous_hash))
                
                new_id, created_at = cur.fetchone()
                
                # 3. Calculate Hash
                data_to_hash = {
                    "id": str(new_id),
                    "user_id": user_id,
                    "activity_type": activity_type,
                    "details": details,
                    "created_at": created_at
                }
                verification_hash = self.audit_service.calculate_hash(data_to_hash, previous_hash)
                
                # 4. Update with Hash
                cur.execute("""
                    UPDATE activity_logs SET verification_hash = %s WHERE id = %s
                """, (verification_hash, new_id))
                
                logger.info(f"Activity logged: {activity_type} for {user_id} (Hash: {verification_hash[:8]}...)")
                
        except Exception as e:
            logger.error(f"Failed to log activity: {e}")
            print(f"DEBUG ERROR: {e}")
            raise e

def get_activity_service() -> ActivityService:
    return ActivityService()
